\section{Datasets}
\label{sec:app-datasets}

	\begin{enumerate}
        \item \textit{Wisconsin Diagnostic Breast Cancer (WDBC)} --- This dataset has 569 instances with 32  variables (ID, diagnosis, 30 real-valued input variables). Each data observation is labeled as benign (357) or malignant (212). Variables are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. Since each data contains the characteristics of 3 nuclei, we have 3 natural views here.\\
        \item \textit{Multi-Features Digital Dataset (MFDD)} --- This dataset consists of features of handwritten numerals (from 0 to 9) extracted from a collection of Dutch utility maps. 200 patterns per class (for a total of 2,000 patterns) have been digitized in binary images. These digits are represented in terms of the following six feature sets, each set being here used as a view: 76 Fourier coefficients of the character shapes, 216 profile correlations, 64 Karhunen-Love coefficients, 240 pixel averages in 2 $\times$ 3 windows and 47 Zernike moments morphological features. Each set of coefficient stands for a view.\\
        \item \textit{Madelon} --- This dataset is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the two classes (corresponding to the +-1 labels). Finally 480 features called `probes' having no predictive power were added by the authors. The order of the features and patterns is random. This dataset is the most challenging among these used here. It is used to test the ability of the tested methods to tackle noise. Because no further information in available on this dataset, the views are randomly generated by picking a random set of 125 features for each.\\
	\item \textit{Isolet} --- This data set was generated as follows: 150 subjects spoke the name of each letter of the alphabet twice. Hence, we have 52 training examples from each speaker. The speakers are grouped into sets of 30 speakers each. The data consists of 1559 instances and 617 variables. All variables are continuous, real-valued scaled variables.\\
	\item \textit{Spam Base} --- The SpamBase data set is composed from 4601 observations described by 57 variables. Every variable describes an e-mail and its category: spam or not-spam. Most of the attributes indicate whether a particular word or character is frequently occurring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. Views can be created using types of attributes.\\
	\item \textit{VHR Strasbourg} --- This dataset~\cite{THRData} is based on a very high spatial resolution image (Pleiades) of the city of Strasbourg. The image was processed using the Multi-Resolution image segmentation (MRIS) algorithm implemented in the eCognition software (c) Definens (2014). A wide range of features available in eCognition are then computed for each segment, including spectral, textural and shape features that were exported in the CSV file. Views can be created according to the type of feature: spectral, texture, and shapes.
	\end{enumerate}

